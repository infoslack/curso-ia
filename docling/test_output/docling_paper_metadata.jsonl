{"extractions": [{"extraction_class": "title", "extraction_text": "Docling Technical Report", "char_interval": {"start_pos": 19, "end_pos": 43}, "alignment_status": "match_exact", "extraction_index": 1, "group_index": 0, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Christoph Auer", "char_interval": {"start_pos": 61, "end_pos": 75}, "alignment_status": "match_exact", "extraction_index": 2, "group_index": 1, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Maksym Lysak", "char_interval": {"start_pos": 76, "end_pos": 88}, "alignment_status": "match_exact", "extraction_index": 3, "group_index": 2, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Ahmed Nassar", "char_interval": {"start_pos": 89, "end_pos": 101}, "alignment_status": "match_exact", "extraction_index": 4, "group_index": 3, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Michele Dolfi", "char_interval": {"start_pos": 102, "end_pos": 115}, "alignment_status": "match_exact", "extraction_index": 5, "group_index": 4, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Nikolaos Livathinos", "char_interval": {"start_pos": 116, "end_pos": 135}, "alignment_status": "match_exact", "extraction_index": 6, "group_index": 5, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Panos Vagenas", "char_interval": {"start_pos": 136, "end_pos": 149}, "alignment_status": "match_exact", "extraction_index": 7, "group_index": 6, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Cesar Berrospi Ramis", "char_interval": {"start_pos": 150, "end_pos": 170}, "alignment_status": "match_exact", "extraction_index": 8, "group_index": 7, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Matteo Omenetti", "char_interval": {"start_pos": 171, "end_pos": 186}, "alignment_status": "match_exact", "extraction_index": 9, "group_index": 8, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Fabian Lindlbauer", "char_interval": {"start_pos": 187, "end_pos": 204}, "alignment_status": "match_exact", "extraction_index": 10, "group_index": 9, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Kasper Dinkla", "char_interval": {"start_pos": 205, "end_pos": 218}, "alignment_status": "match_exact", "extraction_index": 11, "group_index": 10, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Lokesh Mishra", "char_interval": {"start_pos": 219, "end_pos": 232}, "alignment_status": "match_exact", "extraction_index": 12, "group_index": 11, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Yusik Kim", "char_interval": {"start_pos": 233, "end_pos": 242}, "alignment_status": "match_exact", "extraction_index": 13, "group_index": 12, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Shubham Gupta", "char_interval": {"start_pos": 243, "end_pos": 256}, "alignment_status": "match_exact", "extraction_index": 14, "group_index": 13, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Rafael Teixeira de Lima", "char_interval": {"start_pos": 257, "end_pos": 280}, "alignment_status": "match_exact", "extraction_index": 15, "group_index": 14, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Valery Weber", "char_interval": {"start_pos": 281, "end_pos": 293}, "alignment_status": "match_exact", "extraction_index": 16, "group_index": 15, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Lucas Morin", "char_interval": {"start_pos": 294, "end_pos": 305}, "alignment_status": "match_exact", "extraction_index": 17, "group_index": 16, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Ingmar Meijer", "char_interval": {"start_pos": 306, "end_pos": 319}, "alignment_status": "match_exact", "extraction_index": 18, "group_index": 17, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Viktor Kuropiatnyk", "char_interval": {"start_pos": 320, "end_pos": 338}, "alignment_status": "match_exact", "extraction_index": 19, "group_index": 18, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Peter W. J. Staar", "char_interval": {"start_pos": 339, "end_pos": 356}, "alignment_status": "match_exact", "extraction_index": 20, "group_index": 19, "description": null, "attributes": {}}, {"extraction_class": "affiliation", "extraction_text": "AI4K Group, IBM Research", "char_interval": {"start_pos": 358, "end_pos": 382}, "alignment_status": "match_exact", "extraction_index": 21, "group_index": 20, "description": null, "attributes": {}}, {"extraction_class": "affiliation", "extraction_text": "RÃ¼schlikon, Switzerland", "char_interval": {"start_pos": 383, "end_pos": 384}, "alignment_status": "match_lesser", "extraction_index": 22, "group_index": 21, "description": null, "attributes": {}}, {"extraction_class": "version", "extraction_text": "Version 1.0", "char_interval": {"start_pos": 48, "end_pos": 59}, "alignment_status": "match_fuzzy", "extraction_index": 23, "group_index": 22, "description": null, "attributes": {}}, {"extraction_class": "url", "extraction_text": "github.com/DS4SD/docling", "char_interval": null, "alignment_status": null, "extraction_index": 24, "group_index": 23, "description": null, "attributes": {"type": "repository"}}, {"extraction_class": "title", "extraction_text": "Docling Technical Report", "char_interval": {"start_pos": 1674, "end_pos": 1681}, "alignment_status": "match_lesser", "extraction_index": 1, "group_index": 0, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Christoph Auer", "char_interval": null, "alignment_status": null, "extraction_index": 2, "group_index": 1, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Maksym Lysak", "char_interval": null, "alignment_status": null, "extraction_index": 3, "group_index": 2, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Ahmed Nassar", "char_interval": null, "alignment_status": null, "extraction_index": 4, "group_index": 3, "description": null, "attributes": {}}, {"extraction_class": "affiliation", "extraction_text": "AI4K Group, IBM Research", "char_interval": null, "alignment_status": null, "extraction_index": 5, "group_index": 4, "description": null, "attributes": {}}, {"extraction_class": "version", "extraction_text": "Version 1.0", "char_interval": null, "alignment_status": null, "extraction_index": 6, "group_index": 5, "description": null, "attributes": {}}, {"extraction_class": "url", "extraction_text": "github.com/DS4SD/docling", "char_interval": null, "alignment_status": null, "extraction_index": 7, "group_index": 6, "description": null, "attributes": {"type": "repository"}}, {"extraction_class": "title", "extraction_text": "Docling Technical Report", "char_interval": null, "alignment_status": null, "extraction_index": 1, "group_index": 0, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Christoph Auer", "char_interval": null, "alignment_status": null, "extraction_index": 2, "group_index": 1, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Maksym Lysak", "char_interval": null, "alignment_status": null, "extraction_index": 3, "group_index": 2, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "Ahmed Nassar", "char_interval": null, "alignment_status": null, "extraction_index": 4, "group_index": 3, "description": null, "attributes": {}}, {"extraction_class": "affiliation", "extraction_text": "AI4K Group, IBM Research", "char_interval": null, "alignment_status": null, "extraction_index": 5, "group_index": 4, "description": null, "attributes": {}}, {"extraction_class": "version", "extraction_text": "1.0", "char_interval": null, "alignment_status": null, "extraction_index": 6, "group_index": 5, "description": null, "attributes": {}}, {"extraction_class": "url", "extraction_text": "github.com/DS4SD/docling", "char_interval": {"start_pos": 2887, "end_pos": 2911}, "alignment_status": "match_exact", "extraction_index": 7, "group_index": 6, "description": null, "attributes": {"type": "repository"}}, {"extraction_class": "title", "extraction_text": "DocLayNet: A Large Human-Annotated Dataset for Document-Layout Analysis", "char_interval": {"start_pos": 3692, "end_pos": 3765}, "alignment_status": "match_exact", "extraction_index": 1, "group_index": 0, "description": null, "attributes": {}}, {"extraction_class": "author", "extraction_text": "", "char_interval": null, "alignment_status": null, "extraction_index": 2, "group_index": 1, "description": null, "attributes": {}}, {"extraction_class": "affiliation", "extraction_text": "", "char_interval": null, "alignment_status": null, "extraction_index": 3, "group_index": 2, "description": null, "attributes": {}}, {"extraction_class": "version", "extraction_text": "1.0", "char_interval": null, "alignment_status": null, "extraction_index": 4, "group_index": 3, "description": null, "attributes": {}}, {"extraction_class": "url", "extraction_text": "", "char_interval": null, "alignment_status": null, "extraction_index": 5, "group_index": 4, "description": null, "attributes": {"type": "repository"}}], "text": "<!-- image -->\n\n## Docling Technical Report\n\n## Version 1.0\n\nChristoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar\n\nAI4K Group, IBM Research RÂ¨ uschlikon, Switzerland\n\n## Abstract\n\nThis technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.\n\n## 1 Introduction\n\nConverting PDF documents back into a machine-processable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which discards most structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, cloud offerings [3] and most recently, multi-modal vision-language models. As of today, only a handful of open-source tools cover PDF conversion, leaving a significant feature and quality gap to proprietary solutions.\n\nWith Docling , we open-source a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition we developed and presented in the recent past [12, 13, 9]. Docling is designed as a simple, self-contained python library with permissive license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models.\n\nHere is what Docling delivers today:\n\n- Converts PDF documents to JSON or Markdown format, stable and lightning fast\n- Understands detailed page layout, reading order, locates figures and recovers table structures\n- Extracts metadata from the document, such as title, authors, references and language\n- Optionally applies OCR, e.g. for scanned PDFs\n- Can be configured to be optimal for batch-mode (i.e high throughput, low time-to-solution) or interactive mode (compromise on efficiency, low time-to-solution)\n- Can leverage different accelerators (GPU, MPS, etc).\n\n## 2 Getting Started\n\nTo use Docling, you can simply install the docling package from PyPI. Documentation and examples are available in our GitHub repository at github.com/DS4SD/docling. All required model assets 1 are downloaded to a local huggingface datasets cache on first use, unless you choose to pre-install the model assets in advance.\n\nDocling provides an easy code interface to convert PDF documents from file system, URLs or binary streams, and retrieve the output in either JSON or Markdown format. For convenience, separate methods are offered to convert single documents or batches of documents. A basic usage example is illustrated below. Further examples are available in the Doclign code repository.\n\nfrom docling.document\\_converter import DocumentConverter\n\n```\nsource = \"https://arxiv.org/pdf/2206.01062\" # PDF path or URL converter = DocumentConverter() result = converter.convert_single(source) print(result.render_as_markdown()) # output: \"## DocLayNet: A Large Human -Annotated Dataset for Document -Layout Analysis [...]\"\n```\n\nOptionally, you can configure custom pipeline features and runtime options, such as turning on or off features (e.g. OCR, table structure recognition), enforcing limits on the input document size, and defining the budget of CPU threads. Advanced usage examples and options are documented in the README file. Docling also provides a Dockerfile to demonstrate how to install and run it inside a container.\n\n## 3 Processing pipeline\n\nDocling implements a linear pipeline of operations, which execute sequentially on each given document (see Fig. 1). Each document is first parsed by a PDF backend, which retrieves the programmatic text tokens, consisting of string content and its coordinates on the page, and also renders a bitmap image of each page to support downstream operations. Then, the standard model pipeline applies a sequence of AI models independently on every page in the document to extract features and content, such as layout and table structures. Finally, the results from all pages are aggregated and passed through a post-processing stage, which augments metadata, detects the document language, infers reading-order and eventually assembles a typed document object which can be serialized to JSON or Markdown.\n\n## 3.1 PDF backends\n\nTwo basic requirements to process PDF documents in our pipeline are a) to retrieve all text content and their geometric coordinates on each page and b) to render the visual representation of each page as it would appear in a PDF viewer. Both these requirements are encapsulated in Docling's PDF backend interface. While there are several open-source PDF parsing libraries available for python, we faced major obstacles with all of them for different reasons, among which were restrictive\n\n1 see huggingface.co/ds4sd/docling-models/\n\nFigure 1: Sketch of Docling's default processing pipeline. The inner part of the model pipeline is easily customizable and extensible.\n\n<!-- image -->\n\nlicensing (e.g. pymupdf [7]), poor speed or unrecoverable quality issues, such as merged text cells across far-apart text tokens or table columns (pypdfium, PyPDF) [15, 14].\n\nWe therefore decided to provide multiple backend choices, and additionally open-source a custombuilt PDF parser,", "document_id": "doc_5be9205d"}
